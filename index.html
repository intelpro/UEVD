<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="Event-guided Deblurring of Unknown Exposure Time Videos">
    <meta name="author" content="Taewoo Kim,
                                 Jeong-Min Lee,
                                Wang Lin,
                                Kuk-jin Yoon">

    <title>Event-guided Deblurring of Unknown Exposure Time Videos</title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
    <!--    <link rel="icon" href="img/favicon.gif" type="image/gif">-->
</head>

<body>
<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
    <h2>Compare and Reweight: Distinctive Image Captioning <br> Using Similar Images Sets</h2>
<!--            <p class="abstract">An interpretable, data-efficient, and scalable neural scene representation.</p>-->
    <hr>
    <p class="authors">
        <a href="https://wangjiuniu.github.io">Jiuniu Wang</a>,
        <a href="http://wenjiaxu.github.io"> Wenjia Xu</a>,
        <a href="https://visal.cs.cityu.edu.hk/people/qingzhong-wang/">Qingzhong Wang</a>,
        <a href="https://www.cs.cityu.edu.hk/~abchan/"> Antoni B. Chan</a>
        
    </p>
    <div class="btn-group" role="group" aria-label="Top menu">
        <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123460358.pdf" class="btn btn-primary">Paper</a>
        <a href="https://github.com/WangJiuniu/DistinctiveCap" class="btn btn-primary">Code</a>
    </div>
</div>

<div class="container">
	<h2>Introduction</h2>
    <div class="section">
        <div class="vcontainer">
            <iframe class='video' src="https://www.youtube.com/embed/H7so-k0YOz4" frameborder="0"
                    allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen></iframe>
        </div>
        <hr>
        <p>
            A wide range of image captioning models has been developed, achieving significant improvement based on popular metrics, 
		such as BLEU, CIDEr, and SPICE. However, although the generated captions can accurately describe the image, 
		they are generic for similar images and lack distinctiveness, i.e., cannot properly describe the uniqueness of each image. 
		In this paper, we aim to improve the distinctiveness of image captions through training with sets of similar images. 
		First, we propose a distinctiveness metric --- between-set CIDEr (CIDErBtw) to evaluate the distinctiveness of 
		a caption with respect to those of similar images. Our metric shows that the human annotations of each image are not equivalent 
		based on distinctiveness. Thus we propose several new training strategies to encourage the distinctiveness of the generated 
		caption for each image, which are based on using CIDErBtw in a weighted loss function or as a reinforcement learning reward. 
		Finally, extensive experiments are conducted, showing that our proposed approach significantly improves both distinctiveness 
		(as measured by CIDErBtw and retrieval metrics) and accuracy (e.g., as measured by CIDEr) for a wide variety of image captioning baselines. 
		These results are further confirmed through a user study.
        </p>
    </div>

    <div class="section">
        <h2>Qualitative Results</h2>
        <hr>
        <p>
            Here we show qualitative results for the baseline model Transformer+SCST, and our model Transformer+SCST+CIDErBtw.
		The baseline model generates captions that accurately describe the main object, 
		but are quite generic and monotonous, while captions generated by our model are more distinctive in the following aspects. 
		Our captions describe more properties of the main object.
        </p>
	<div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="images/Q1.png" style="width:100%">
            </div> 
        </div>
	<div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="images/Q2.png" style="width:100%">
            </div> 
        </div>
    </div>

   
    <div class="section">
        <h2>Paper</h2>
        <hr>
        <div>
           <div class="list-group">
                <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123460358.pdf"
                   class="list-group-item">
                    <img src="images/paper_thumbnail.png" style="width:100%;">
                    <!-- <img src="images/paper_thumbnail.png" style="width:100%; margin-right:-20px; margin-top:-10px;">
                    -->
                </a>
            </div>
        </div>
    </div>

    <div class="section">
        <h2>Bibtex</h2>
        <hr>
        <div class="bibtexsection">
    @inproceedings{wang2020compare,
        title={Compare and Reweight: Distinctive Image Captioning Using Similar Images Sets},
        author={Wang, Jiuniu and Xu, Wenjia and Wang, Qingzhong and Chan, Antoni B},
        booktitle={ECCV},
        year={2020}
    }
        </div>
    </div>

    <hr>

    <footer>
        <p>Send feedback and questions to <a href="https://wangjiuniu.github.io/">Jiuniu Wang</a></p>
    </footer>
</div>


<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

</body>
</html>
